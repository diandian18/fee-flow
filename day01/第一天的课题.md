# 前端监控概述

## 本次训练营规划

1. 前端监控概述、前端监控系统架构、fee仓库
2. nginx配置、创建sdk demo并测试
3. kafka和filebeat配置
4. 部署mysql和redis，修改fee，并部署server部分
5. 部署client部分，串起整体流程

## 1. 为什么需要做前端监控

如果没有前端监控，我们的前端项目在线上“裸奔”：
    1. 那么我们不会知道我们写的代码，在不同系统、不同浏览器、不同网络环境条件下，有没有缺陷？页面访问的速度快还是慢？只能等待用户反馈，可能用户反馈过来的时候，已经在抱怨了。即使反馈，用户还不一定能全面保留案发现场的信息，我们可能很难复现问题。
    2. 我们不知道我们的用户访问量、菜单点击量、用户停留时长等信息，我们好不容易开发出来的产品，可能根本没有人使用而我们自己不知道。
    3. 我们缺乏浏览器型号、版本和对应用户使用量等对处理前端兼容性至关重要的信息。

## 2. 前端监控目标

### 2.1 稳定性（stability）

### 2.2 用户体验（experience）

### 2.3 业务（business）

## 3. 常见前端监控方案对比

## 4. 前端监控系统架构

我们首先设计一下我们的系统架构

![前端监控系统架构图](../assets/fee-flow.png)

总体上我们的架构由6个大的部分组成：

1. `sdk`安装在前端业务项目中，用来采集错误、性能、业务等信息并上报到`打点服务`
2. `dig server`即`打点服务`，用来提供一个`空gif`的`nginx`服务，并且利用`nginx`生成`日志文件`，另外需要一个`filebeat`，来监听这些日志文件，并将这些文件内容发送到`kafka`消息队列
3. `kafka`是分布式发布-订阅消息系统，`kafka`会接受`生产者(producer)`的消息，并且把消息发送给订阅消息的`消费者(consumer)`。上面的`filebeat`就是生产者，而下面的`消费服务`就是消费者
4. `server`包含两部分
    1. 我们需要一个`消费服务`，用来消费kafka的日志消息，并且对这些日志做格式校验、聚合等操作后落入`mysql`数据库持久化。
    2. 另外还需要一个`rest api`服务，对错误、性能、业务等信息做可视化展示用
5. `mysql`和`redis`，对消费后的数据做持久化和缓存
6. `可视化展示client`直观展示监控到的数据

## 4. fee介绍

> [fee（灯塔）](https://github.com/LianjiaTech/fee) 是前端监控系统，贝壳找房主要前端监控系统，服务公司上百条产品线。 特点：架构简单、轻量、支持私有化部署。可收集前端设备、系统、环境信息， 可以对前端页面js报错、资源错误、性能指标进行配置报警等， 并且可以通过上报错误信息引导用户快速定位解决问题。

我们选择灯塔fee帮助我们搭建前端监控系统，但是fee没有提供完整的架构和整体解决方案。

灯塔fee提供了架构中`sdk`、`server`和`client`三个部分，其他部分`dig server`、`kafka`和`mysql/redis`，需要我们自行开发或搭建。

## 3. fee仓库

我们首先`clone`仓库到本地：

```bash
git clone https://github.com/LianjiaTech/fee
cd fee
```

可以看到，fee仓库由`sdk`、`server`和`client`三个部分组成。

```bash
├── README.md
├── sdk
├── server
└── client
```

我们可以稍微花点时间过一下仓库的代码，了解下代码结构，使用方式和运行原理。这里先不做展开。